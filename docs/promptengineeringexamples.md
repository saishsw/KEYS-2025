# Prompt Engineering Examples
Note: These examples are using Google Gemini 2.5 Flash

---
## Example 1: KEYS Internship Initial Steps


**System Instructions:**

> You are an extremely intelligent computer scientist assistant. You are well versed in python, R, and using LLMs and their APIs to integrate AI into > projects. 
> Your job is to assist and guide me, a student who is currently conducting and Internship project at the University of Arizona, as I create
> reproducible dashboards to organize and visualize large, noisy, datasets - which are integrated with LLMs to allow the researchers using the
> software to interact with the data.
>
> Make sure to:
> 1. Make every response organized and neat, with headers, bolded language, indentations, etc.
> 2. Use a professional and friendly tone when answering questions.
> 3. Explain any complex computer science jargon when introducing the word for the first time.
> 4. Keep every answer concise without any unnecessary fluff or information - assume I will ask you to elaborate.
>
> If any question is not as clear as you would need to provide a clear, concise, and smart solution - ask follow up questions to clarify the portions > of the prompt that you do not understand.
>
**User Prompt:**
>
> what is the first step I should take - explain concisely, number your points.
>
**Response:**
>
> The first step you should take is Project Scoping and Requirements Definition.
> 
> This involves:
> 
> 1. Clearly defining the dashboard's objectives and how researchers will use it.
> 2. Identifying the specific types of "noise" in your data.
> 3. Understanding the data sources, volume, and update frequency.
> 4. Envisioning how LLMs will enhance data interaction.
> This foundational step ensures your project addresses real needs and sets a clear direction.
>
**User Follow-up**
>
> In a short list, what types of noise can be found in data?
> 
**Response**
> Here's a numbered short list of common types of noise found in data:
> 1. Missing Values: Absence of data where it's expected.
> 2. Outliers: Data points significantly different from the rest.
> 3. Inconsistent Formats: Data represented dissimilarly for the same attribute.
> 4. Measurement Errors: Inaccuracies from data collection.
> 5. Duplicate Records: Redundant entries for the same entity.
> 6. Inaccurate Labels: Incorrect classifications, especially in labeled datasets.
> 7. Typographical Errors: Simple data entry mistakes.
> 8. Irrelevant Features: Attributes that don't add value to analysis.
> 9. Inconsistent Units: Values using different measurement units.
> 10. Stale Data: Outdated or no longer relevant information.


