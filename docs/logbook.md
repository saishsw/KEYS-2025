# Logbook


## Training Week


### 6/2/2025
### 6/3/2025
### 6/4/2025
### 6/5/2025
### 6/6/2025

## KEYS Internship

### 6/9/2025
Today, I started with learning how to use the Discovery Environment on CyVerse - which allows me to run applications such as Visual Studio Code(VS Code), RStudio, and Jupyter Notebook. Next, I started building my Vibe coding setup by downloading Cline - an AI Autonomous Coding Agent for VS Code, and I encountered a roadblock when trying to generate a Google Gemini API to use in Cline - I didn't have permission to generate a Gemini API Key. Then set up Github Copilot on VS Code as well as turning on MCP(Model Context Protocol) integration into VS Code. I followed this with completing [KEYS Assignment 1: Internship Description](assignment1.md). Next, I started learning about the current AI Landscape, the Ethics of AI, and Prompt Engineering using Dr. Tyson Swetnam's [Generative AI and Prompt Engineering Workshop](https://tyson-swetnam.github.io/intro-gpt/). I practiced these prompt engineering skills using by writing these [Prompt Engineering Examples](promptengineeringexamples.md). 
### 6/10/2025
Today, I revisted the Gemini API generation issue, and I learned that Dr. Swetnam needs to go into the system and give me permission to generate an API Key from UofA's Gemini. As Dr. Swetnam was working on that, I used [CyVerse's Verde AI](https://chat.cyverse.ai/) to generate an API Key to use in Cline. I originally  used the Deepseek-R1 model, but it was too verbose and glitchy, so I switched to the llama-4-scout model, which worked better with Cline. Next, I downloaded [File System](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem), an MCP Server, into Cline, which allows Cline to read, write, create, delete, and much more regarding my files. Then, after some testing, Dr. Swetnam fixed the permissions issue, and I was able to generate a Gemini API Key and use it to power Cline - making my setup even more powerful. I used Dr. Swetnam's [MapMaking 101](https://tyson-swetnam.github.io/intro-gpt/tutorials/publichealth/gis/) to use Cline to create a Public Health Map, however, I got timedout on using the API for exceeding its Token limit at 1.6 million tokens. So I decided to switch back to VerdeAI, which has no limit, to create the Public Health Map. After multiple attemps with both LLMs, I learned of the limitations of LLMs in the modern day, as both of them couldn't complete [Step 5](https://tyson-swetnam.github.io/intro-gpt/tutorials/publichealth/gis/#step-5-build-a-storytelling-leaflet-map) consistently. After a few more attempts, Verde created an HTML file for the final output - but it was incomplete and missing data. After many attempts, I went to get help from an external [ChatGPT-4o](https://openai.com/index/hello-gpt-4o/), which helped me fix my code. I pushed it to github and opened a website using Github Pages: view [London Public Health Data](https://saishsw.github.io/London-Public-Health-Map/). I then went to D2L and completed the questions assignment for our upcoming speaker, Dr. Vignesh Subbian.
### 6/11/2025
I started the day with our first Science Seminar - which happens each wednesday morning - where I learned about Neural Networks and Clinical work with Dr. Vignesh Subbian, then we discussed our first reflection, and moved on with various annoucements concering posters, late work, and how the program will be running. Then I joined our KEYS Crew meeting, where we discussed then to schedule our recurring meetings, how logistics for the social events will work, and when to set up individual meetings with our KEYS Crew Leader. Then, I checked into lab, and started learning about [Reproducibility I: Software Environments](https://foss.cyverse.org/06_reproducibility_I/) on [CyVerse Foundational Open Science Skills 2024](https://foss.cyverse.org/) (FOSS) course. I learned about how Environment Managers can be a solution "Software Dependency Hell" by allowing your computers to create unique software installation directories to run the software in - that are isolated from your computer's PATH. Then I learned how to create and manage my own custom environment in [Conda](https://docs.conda.io/projects/conda/en/stable/user-guide/getting-started.html) (a python Environment Manager) and run a python script that outputs the Mandelbrot set. Then, I downloaded [Docker](https://hub.docker.com/), a program to assist in the delivery of reproducible science.
### 6/12/2025
I started by learning FOSS's [Reproducibility II: Run Containers](https://foss.cyverse.org/07_reproducibility_II/). However, to follow along, I need to access [GitHub Codespaces](https://github.com/education), which requires me to signed up to [GitHub Education](https://github.com/education). So I applied for GitHub education with my unofficial transcript, and it should take at least a few days for me to know whether or not my application has been accepted. In the meanwhile, I used VS Code on my local device so follow along with the lesson. Through this lesson, I learned: fundamental Docker commands, how to pull an image and run the container on my computer, and learned about ports. After this, I learned that my GitHub Education application was unable to be verified due to authentication issues, so I spent time setting up my two-factor authentication system and updating my billing information, and re-applying. Once this was done, I moved on to the next FOSS lesson [Reproducibility III: Building Docker Containers](https://foss.cyverse.org/08_reproducibility_III/). I learned that I needed access to GitHub Codespaces to do the lesson, and, thankfully, my GitHub Education application was acceppted. Even though I need to wait 72 Hours to access the benefits of GitHub Education, I was able to use Codespaces, so I continued with the lesson. In this lesson I learned how to run an example container - the one I ran was [this](https://github.com/jeffgillan/r-script-containerized), and I also learned how to build my own Docker images. Then I learned about CyVerse through the [Remote Computing with Cyverse](https://foss.cyverse.org/09_remote_computing_cyverse/) lesson. Then, with the help of a fellow intern, I set up filesystem and [Fetch](https://github.com/modelcontextprotocol/servers/tree/main/src/fetch) on Cyverse's discovery environment's VS Code.
### 6/13/2025
I started today by downloading Fetch, the MCP Server mentioned on the day above, onto my local computer as well. This will allow me to use its features when I am coding on the Cyverse discovery environment and when I am coding on my local device. Next I started learning about [SQL](https://en.wikipedia.org/wiki/SQL) through the [Databases and SQL: Software Carpentry Lesson](https://swcarpentry.github.io/sql-novice-survey/index.html), and to follow along with the lesson, I dowloaded [DB Browser for SQLite](https://sqlitebrowser.org/about/). This lesson walked me through the common commands used in SQL by analyzing [this dataset](https://swcarpentry.github.io/sql-novice-survey/files/survey.db). I learned techniques such as sorting, filtering, calculating statistics, and data hygiene. At the very end of the lesson, I revied python and R - as they are languages commonly used to analyze large amounts of data. I then put these skills to practice by downloading [DuckDB](https://duckdb.org/), however, I was unsure how to use it - so I watched a tutorial video on YouTube guiding me through the usefulness and practically of using DuckDB. After learning how to use DuckDB with python, I downloaded [Quarto](https://quarto.org/) which allows me to create clean and organized visualization, which are needed for my project of creating interactive databases. Lastly I looked into [Marimo](https://marimo.io/), an open-source python notebook with SQL already integrated, as Dr. Merchant mentioned that it would be important and a helpful tool in completing my project.
